{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai2.vision.all import *\n",
    "import torchaudio\n",
    "import torchaudio.transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fastai2-resnet-audio model\n",
    "\n",
    "> ResNet-like 1D CNN model for audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "- fastai2\n",
    "- torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet-like 1D CNN\n",
    "\n",
    "This code is inspired by https://www.kaggle.com/readilen/resnet-for-mnist-with-pytorch, https://towardsdatascience.com/understanding-and-visualizing-resnets-442284831be8 and \n",
    "https://github.com/fastai/fastai2/blob/master/nbs/11_vision.models.xresnet.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def conv1xk(in_channels, out_channels, kernel_size=3, stride=1):\n",
    "    padding = kernel_size // 2\n",
    "    return nn.Conv1d(in_channels, out_channels, kernel_size=kernel_size,\n",
    "                    stride=stride, padding=padding, bias=False)\n",
    "\n",
    "def init_cnn_1d(m):\n",
    "    if getattr(m, 'bias', None) is not None: nn.init.constant_(m.bias, 0)\n",
    "    if isinstance(m, (nn.Conv1d,nn.Linear)): nn.init.kaiming_normal_(m.weight)\n",
    "    for l in m.children(): init_cnn_1d(l)\n",
    "        \n",
    "def  splitter(m):\n",
    "    return L(m[0][:6], m[0][6:], m[1]).map(params)\n",
    "\n",
    "# Residual block\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, downsample=None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = conv1xk(in_channels, out_channels, kernel_size, stride)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv1xk(out_channels, out_channels, kernel_size)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(residual)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "class ResNetAudio(nn.Sequential):\n",
    "    def __init__(self, block, layers, in_channels=64, num_classes=10, kernel_size=3, stride=2, dropout=0.2):\n",
    "        in_block = [] # input block\n",
    "        residual_block = [] # residual blocks\n",
    "        header_block = [] # linear head\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.block = block\n",
    "        \n",
    "        in_kernel_size = kernel_size * 2 + 1\n",
    "        \n",
    "        in_block.append(conv1xk(1, in_channels, in_kernel_size, stride))\n",
    "        in_block.append(nn.BatchNorm1d(in_channels))\n",
    "        in_block.append(nn.ReLU(inplace=True))\n",
    "        in_block.append(nn.MaxPool1d(kernel_size, stride, kernel_size//3))\n",
    "        \n",
    "        residual_block = self.make_blocks(layers, in_channels, kernel_size, stride)\n",
    "        \n",
    "        header_block.append(nn.AdaptiveAvgPool1d(1))\n",
    "        header_block.append(nn.Flatten())\n",
    "        header_block.append(nn.Dropout(dropout))\n",
    "        header_block.append(nn.Linear(in_channels*2**(len(layers)-1), num_classes))\n",
    "        \n",
    "        super().__init__(nn.Sequential(*in_block, *residual_block),nn.Sequential(*header_block))\n",
    "        init_cnn_1d(self)\n",
    "\n",
    "    def make_blocks(self, layers, in_channels, kernel_size, stride):\n",
    "        return [self.make_layer(self.block, in_channels*2**i, l, kernel_size, stride) for i, l in enumerate(layers)]\n",
    "        \n",
    "    def make_layer(self, block, out_channels, blocks, kernel_size=3, stride=1):\n",
    "        downsample = None\n",
    "        if (stride != 1) or (self.in_channels != out_channels):\n",
    "            downsample = nn.Sequential(\n",
    "                conv1xk (self.in_channels, out_channels, kernel_size=kernel_size, stride=stride),\n",
    "                nn.BatchNorm1d(out_channels))\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, kernel_size, stride, downsample))\n",
    "        self.in_channels = out_channels\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(out_channels, out_channels, kernel_size))\n",
    "        return nn.Sequential(*layers)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tunable model\n",
    "\n",
    "Call replace_head(learn.model, num_classes=<new_num_classes>) to adapt the model head to a new dataset (new number of classes). Now you can use learn.fine_tune(), learn.unfreeze() and learn.fit_one_cycle() to fine-tune the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def replace_head(model, num_classes):\n",
    "    model[-1][-1] = nn.Linear(512, num_classes)\n",
    "    apply_init(model[1], nn.init.kaiming_normal_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations\n",
    "\n",
    "Configurations for **ResNet18 / ResNet34-like** architectures. Kernel size 34 and stride 4 seem to work quite \n",
    "well. But there is still room for experimentation and improvement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "# resnet 18\n",
    "resnet1d18 = {\n",
    "    \"block\": ResidualBlock,\n",
    "    \"layers\": [2, 2, 2, 2],\n",
    "    \"in_channels\": 64,\n",
    "    \"kernel_size\": 15,\n",
    "    \"stride\": 4,\n",
    "    \"num_classes\": 10\n",
    "}\n",
    "\n",
    "# resnet 34\n",
    "resnet1d34 = {\n",
    "    \"block\": ResidualBlock,\n",
    "    \"layers\": [3, 4, 6, 3],\n",
    "    \"in_channels\": 64,\n",
    "    \"kernel_size\": 15,\n",
    "    \"stride\": 4,\n",
    "    \"num_classes\": 10\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test architecutre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "bs = 8\n",
    "arch = resnet1d18\n",
    "model = ResNetAudio(**arch)\n",
    "inp = torch.randn(bs,1,22050)\n",
    "out = model(inp)\n",
    "assert len(out) == bs\n",
    "assert len(out[0]) == arch['num_classes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test replace_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "num_classes = 22\n",
    "replace_head(model, num_classes)\n",
    "assert getattr(model[-1][-1], 'out_features') == num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit ('fastai2': conda)",
   "language": "python",
   "name": "python38164bitfastai2conda8f00f3245bb84569a74bc3f339ede271"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
