{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai_resnet_audio.model import *\n",
    "from fastai_resnet_audio.data import *\n",
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fastai_resnet_audio tutorial\n",
    "\n",
    "> Tutorial for fastai-resnet-audio - Dataset used: https://github.com/earthspecies/open_collaboration_on_audio_classification/blob/master/introduction.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/Users/florian/.fastai/data/macaques_24414Hz')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data('https://storage.googleapis.com/ml-animal-sounds-datasets/macaques_24414Hz.zip')\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoaders\n",
    "\n",
    "Create DataBlock and DataLoaders with AudioBlock and AudioTransforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 0.5\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "dblocks = DataBlock(blocks = (AudioBlock,CategoryBlock),\n",
    "                 get_items=get_files, \n",
    "                 splitter=RandomSplitter(seed=42),\n",
    "                 get_y=parent_label,\n",
    "                 item_tfms=[AudioRandomCrop(length=length),\n",
    "                            AudioFixLength(length=length),\n",
    "                           ],\n",
    "                 batch_tfms=[AudioAddNoise(device=device)]\n",
    "                 )\n",
    "\n",
    "dls=dblocks.dataloaders(path, bs=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorAudio([[[-7.4502e-02, -9.2339e-02, -1.0822e-01,  ...,  2.2105e-02,\n",
       "            2.0925e-02,  2.0883e-02]],\n",
       " \n",
       "         [[ 3.2130e-01,  3.5341e-01,  3.7791e-01,  ..., -3.3554e-02,\n",
       "           -2.9873e-02, -2.7081e-02]],\n",
       " \n",
       "         [[-2.2488e-02, -4.8285e-02, -7.2340e-02,  ..., -2.6424e-01,\n",
       "           -2.5225e-01, -2.3800e-01]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 1.0335e-03, -8.5275e-04, -1.1653e-03,  ...,  1.9616e-04,\n",
       "           -1.2397e-03,  1.9258e-04]],\n",
       " \n",
       "         [[ 7.0962e-04,  8.3948e-04, -3.5992e-04,  ...,  3.3023e-04,\n",
       "           -5.8667e-04, -7.5844e-04]],\n",
       " \n",
       "         [[ 8.7482e-04,  7.2337e-04, -1.8100e-04,  ...,  1.1790e-03,\n",
       "           -5.3216e-04,  1.7107e-04]]]),\n",
       " TensorCategory([6, 6, 6, 0, 6, 6, 6, 4, 6, 5, 5, 4, 4, 6, 0, 3, 6, 2, 6, 3, 2, 5, 2, 7,\n",
       "         5, 3, 3, 6, 2, 0, 0, 2, 0, 2, 3, 5, 5, 3, 5, 6, 0, 0, 6, 5, 4, 7, 3, 3,\n",
       "         2, 3, 3, 0, 5, 6, 4, 0, 3, 3, 5, 7, 0, 2, 5, 4, 4, 7, 5, 5, 3, 6, 5, 5,\n",
       "         3, 6, 6, 1, 2, 0, 1, 3, 3, 1, 0, 6, 3, 1, 0, 0, 3, 2, 0, 7, 5, 6, 4, 4,\n",
       "         3, 7, 6, 4, 6, 1, 4, 3, 2, 5, 3, 4, 6, 4, 3, 7, 4, 2, 5, 2, 2, 6, 4, 1,\n",
       "         2, 6, 3, 6, 4, 4, 0, 2]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls.one_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Create **model configuration** - available configurations are resnet1d18 and resnet1d34.\n",
    "\n",
    "You have to adopt the **num_classes** parameter according to the number of classes of your dataset (8 classes for this dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = resnet1d18\n",
    "config['num_classes'] = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'block': fastai_resnet_audio.model.ResidualBlock,\n",
       " 'layers': [2, 2, 2, 2],\n",
       " 'in_channels': 64,\n",
       " 'kernel_size': 15,\n",
       " 'stride': 4,\n",
       " 'num_classes': 8}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create **model** using config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetAudio(\n",
       "  (0): Sequential(\n",
       "    (0): Conv1d(1, 64, kernel_size=(31,), stride=(4,), padding=(15,), bias=False)\n",
       "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool1d(kernel_size=15, stride=4, padding=5, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Conv1d(64, 64, kernel_size=(15,), stride=(4,), padding=(7,), bias=False)\n",
       "        (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv1d(64, 64, kernel_size=(15,), stride=(1,), padding=(7,), bias=False)\n",
       "        (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv1d(64, 64, kernel_size=(15,), stride=(4,), padding=(7,), bias=False)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (conv1): Conv1d(64, 64, kernel_size=(15,), stride=(1,), padding=(7,), bias=False)\n",
       "        (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv1d(64, 64, kernel_size=(15,), stride=(1,), padding=(7,), bias=False)\n",
       "        (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Conv1d(64, 128, kernel_size=(15,), stride=(4,), padding=(7,), bias=False)\n",
       "        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv1d(128, 128, kernel_size=(15,), stride=(1,), padding=(7,), bias=False)\n",
       "        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv1d(64, 128, kernel_size=(15,), stride=(4,), padding=(7,), bias=False)\n",
       "          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (conv1): Conv1d(128, 128, kernel_size=(15,), stride=(1,), padding=(7,), bias=False)\n",
       "        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv1d(128, 128, kernel_size=(15,), stride=(1,), padding=(7,), bias=False)\n",
       "        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Conv1d(128, 256, kernel_size=(15,), stride=(4,), padding=(7,), bias=False)\n",
       "        (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), bias=False)\n",
       "        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv1d(128, 256, kernel_size=(15,), stride=(4,), padding=(7,), bias=False)\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (conv1): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), bias=False)\n",
       "        (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), bias=False)\n",
       "        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Conv1d(256, 512, kernel_size=(15,), stride=(4,), padding=(7,), bias=False)\n",
       "        (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv1d(512, 512, kernel_size=(15,), stride=(1,), padding=(7,), bias=False)\n",
       "        (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv1d(256, 512, kernel_size=(15,), stride=(4,), padding=(7,), bias=False)\n",
       "          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (conv1): Conv1d(512, 512, kernel_size=(15,), stride=(1,), padding=(7,), bias=False)\n",
       "        (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv1d(512, 512, kernel_size=(15,), stride=(1,), padding=(7,), bias=False)\n",
       "        (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): AdaptiveAvgPool1d(output_size=1)\n",
       "    (1): Flatten()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=512, out_features=8, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNetAudio(**config)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learner + Training\n",
    "\n",
    "Creating the **learner and trainig** the model is straight forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, model, metrics=accuracy, cbs=ShowGraphCallback())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/3 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      2.22% [1/45 00:06<04:39]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(5, 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tune pretrained model on different dataset\n",
    "\n",
    "**Steps**\n",
    "- create DataLoaders\n",
    "- create model with same config (num_classes) as the pretrained model\n",
    "- create learner\n",
    "- load pretrained model weights with learn.load(\"pretrained.pth\")\n",
    "- call **replace_head** with num_classes=number classes new dataset\n",
    "\n",
    "Lets pretend the macaques dataset had 20 instead of 8 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data('https://storage.googleapis.com/ml-animal-sounds-datasets/macaques_24414Hz.zip')\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 0.5\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "dblocks = DataBlock(blocks = (AudioBlock,CategoryBlock),\n",
    "                 get_items=get_files, \n",
    "                 splitter=RandomSplitter(seed=42),\n",
    "                 get_y=parent_label,\n",
    "                 item_tfms=[AudioRandomCrop(length=length),\n",
    "                            AudioFixLength(length=length),\n",
    "                           ],\n",
    "                 batch_tfms=[AudioAddNoise(device=device)]\n",
    "                 )\n",
    "\n",
    "dls=dblocks.dataloaders(path, bs=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model was pretrained on dataset with 8 classes, so create config with 8 classes to load the pretrianed model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = resnet1d18\n",
    "config['num_classes'] = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, model, metrics=accuracy, cbs=ShowGraphCallback())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load(\"saved_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading the pretrained weights we can **replace the last linear layer**. In this example for a dataset with **20 classes**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_head(learn.model, num_classes=20)\n",
    "model[-1][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastaidev",
   "language": "python",
   "name": "fastaidev"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
